{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2\n",
    "## Решение СЛАУ прямыми и итерационными методами\n",
    "Выполнил: Шумаков Иван Б01-009\n",
    "\n",
    "Прямой метод - метод Холецкого\n",
    "\n",
    "Итерационный - метод верхней релаксации\n",
    "\n",
    "Анализ проводился по первой норме\n",
    "\n",
    "### Начальные данные\n",
    "Анализ проводился для матрицы пункта `л)`\n",
    "$$ \\begin{cases}\n",
    "    a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n} x_n = f_1 \\\\\n",
    "    \\dots                                              \\\\\n",
    "    a_{n1} x_1 + a_{n2} x_2 + \\dots + a_{nn} x_n = f_n \\\\   \n",
    "   \\end{cases}  $$\n",
    "$$ n = 20, a_{ii} = 10, a_{ij} = 1 / (i + j), f_i = 1 / i $$\n",
    "\n",
    "### Итерационный метод\n",
    "Общая формула для метода верхних релаксаций:\n",
    "$$  x_j^{i + 1} = -\\tau \\sum_{k = 1}^{j - 1} \\frac{a_{jk}}{a_{jj}}x_k^{i + 1}\n",
    "    + (1 - \\tau)x_j^i - \\tau \\sum_{k = j + 1}^n \\frac{a_{jk}}{a_{jj}}k_k^i\n",
    "    + \\tau \\frac{f_i}{a_{jj}} $$\n",
    "\n",
    "Критерий останова для метода верхних релаксаций:\n",
    "$$ ||x^{k + 1} - x ^k|| < \\epsilon   $$\n",
    "$$ \\epsilon = 0.01 $$\n",
    "\n",
    "Невязка на каждом шаге выражается формулой:\n",
    "$$ r_k = || A x^k - f || $$\n",
    "\n",
    "### Прямой метод\n",
    "В качестве прямого метода был выбран метод Холецкого:\n",
    "$$ A = L L^T $$\n",
    "$$  \\begin{cases}\n",
    "        L y = f \\\\\n",
    "        L^T x = y\n",
    "    \\end{cases} $$\n",
    "\n",
    "Коэффициенты матрицы L выражаются как:\n",
    "$$ l_{ij} = \\frac{1}{l_{jj}} (a_{ij} - \\sum_{k = 1}^{j - 1} l_{ik} j_{jk}) $$\n",
    "$$ l_{ii} = \\sqrt{a_{ii} - \\sum_{k = 1}^{i - 1} l_{ik}^2} $$\n",
    "\n",
    "### Анализ матрицы\n",
    "Число обусловленности:\n",
    "$$ \\mu = ||A||A^{-1}|| $$\n",
    "\n",
    "Поиск $\\lambda_{min} \\lambda_{max}$ степенным методом:\n",
    "\n",
    "$$  y_k = A y_{k - 1} \\\\\n",
    "    \\lambda_{max} = \\frac{||y_k||}{||y_{k - 1}||} $$\n",
    "\n",
    "Гуманитарное объяснение метода:\n",
    "\n",
    "Представим этот итерационный процесс в базисе собственных векторов. Пусть начальный вектор имеет компоненты по всем осям, тогда на каждой итерации его составляющие по каждому из базисных векторов будут умножаться на соответствующие собственные значения. Таким образом составляющая по базисному вектору с максимальным собственным значением будет расти быстрее остальных(отсюда можно сделать оценку, что сходимость это геом. прогрессия) и в пределе бесконечности $y_k$ будет направлен по базисному вектору с максимальным собственным значением. Поэтому на новой итерации этот ветор будет просто умножаться на максимальное собственное значение.\n",
    "\n",
    "Для поиска минимального собственного значения необходимо заменить $A -> A^{-1}$ и разделить 1 на получившееся число:\n",
    "\n",
    "$$  y_k = A^{-1} y_{k - 1} \\\\\n",
    "    \\lambda_{min} = 1 / \\frac{||y_k||}{||y_{k - 1}||} $$\n",
    "\n",
    "(эти выводы слкдуют из рассуждений выше как обратный процесс преобразования)\n",
    "\n",
    "Из этого объяснения можно сделать неутешительный вывод: если начальный вектор не имеет компоненты по базисному вектору с максимальным собственным значением, то он не будет к нему сходиться. Таким образом начальных векторов, которые будут выдавть неправильный ответ, бесконечно много.\n",
    "\n",
    "## Выоды\n",
    "Ответы, полученные с помощью разных, методов сходятся с разницей во второй - третьей значащих цифрах.\n",
    "Степенной метод поиска собственных значений сходится с точным решением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "конечная разность: 0.008235196572854153\n",
      "Ответ методом верхних релаксаций: [0.09347738 0.04482422 0.02913087 0.02144176 0.01689773 0.01390572\n",
      " 0.01179117 0.01022005 0.00900831 0.0080463  0.00726471 0.0066176\n",
      " 0.00607335 0.00560947 0.00520956 0.00486139 0.00455563 0.00428505\n",
      " 0.00404399 0.0038279 ]\n",
      "Ответ методом Холецкого: [0.09615746 0.04478375 0.02874755 0.02101576 0.0164943  0.01353947\n",
      " 0.01146294 0.00992677 0.00874602 0.00781115 0.00705327 0.00642689\n",
      " 0.0059008  0.00545292 0.00506717 0.00473155 0.00443698 0.00417641\n",
      " 0.00394434 0.00373636]\n",
      "Невязка: [5.3319564  2.94257316 1.591187   0.84382867 0.43901868 0.22405194\n",
      " 0.11208979 0.05490131 0.02627231]\n",
      "\n",
      "Число обусловленности 1.4526954762585125\n",
      "Максиммальное собственное значение: 11.300128398304816\n",
      "Минимальное собственное значение через A^-1: 9.658552341348045\n",
      "\n",
      "Реальные собственные значения для : [ 9.65779712  9.8117211   9.86808709  9.89787972  9.91645175  9.92919102\n",
      "  9.93849622  9.94560315  9.95121536  9.95576376  9.95952748  9.96269555\n",
      "  9.9654007   9.96773913  9.96978247  9.97158578  9.97319345  9.97464763\n",
      " 10.08309313 11.3001284 ]\n"
     ]
    }
   ],
   "source": [
    "# %load 'Matrix.py'\n",
    "import numpy as np             \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 20\n",
    "diag = 10\n",
    "\n",
    "class Norm:\n",
    "\n",
    "    #возвращает максимальную сумму в строке\n",
    "    def max_sum(matrix):\n",
    "        max = np.sum(np.abs(matrix[0]))\n",
    "        for line in matrix:\n",
    "            cur_sum = np.sum(np.abs(line))\n",
    "            if cur_sum > max:\n",
    "                max = cur_sum\n",
    "        return max\n",
    "\n",
    "    def __get_first_norm(matrix):\n",
    "        matr_size = matrix.shape\n",
    "        if len(matr_size) != 1:\n",
    "            return Norm.max_sum(matrix)\n",
    "        else:\n",
    "            return np.amax(np.abs(matrix))\n",
    "\n",
    "    def get_norm(matrix):\n",
    "        return Norm.__get_first_norm(matrix)\n",
    "\n",
    "\n",
    "class UpperRelax:\n",
    "\n",
    "    def __init__(self, A, f):\n",
    "        self.A = A\n",
    "        self.f = f\n",
    "        self.teta = 1.5\n",
    "        self.epsilon = 0.01\n",
    "        matr_size = A.shape\n",
    "        if (len(matr_size) != 2) or (matr_size[0] != matr_size[1]):\n",
    "            print('Incorrect matrix')\n",
    "        self.n = matr_size[0]\n",
    "        self.r_arr = np.array([])\n",
    "\n",
    "    def __get_initial_x(self):\n",
    "        x = np.copy(self.f)\n",
    "        return x\n",
    "\n",
    "    #подсчет невязки\n",
    "    def __calc_r(self, x):\n",
    "        r = Norm.get_norm(np.matmul(self.A, x) - self.f)\n",
    "        self.r_arr = np.append(self.r_arr, r)\n",
    "\n",
    "    #концы включены\n",
    "    #х - массив\n",
    "    def __sum(self, start, end, x, j):\n",
    "        sum = 0.0\n",
    "        for k in range(end - start + 1):\n",
    "            sum += self.A[j, start + k] / self.A[j, j] * x[start + k]\n",
    "        return sum\n",
    "\n",
    "    #индексация с 0\n",
    "    def __iteration(self, x_prev):\n",
    "        x_new = np.array([])\n",
    "        for j in range(self.n):\n",
    "            x_j = (-1) * self.teta * self.__sum(0, j - 1, x_new, j) + (1 - self.teta) * x_prev[j] \\\n",
    "                - self.teta * self.__sum(j + 1, self.n - 1, x_prev, j) + self.teta * self.f[j] / self.A[j, j]\n",
    "            x_new = np.append(x_new, x_j)\n",
    "        return x_new\n",
    "    \n",
    "    def calculate(self):\n",
    "        num_of_iter = 0.0\n",
    "        x_prev = self.__get_initial_x()\n",
    "        x_new = np.array([])\n",
    "        prev_error = np.Inf\n",
    "        curr_error = 0.0\n",
    "        while True:\n",
    "            x_new = self.__iteration(x_prev)\n",
    "            self.__calc_r(x_new)\n",
    "            curr_error = Norm.get_norm(x_new - x_prev)\n",
    "            if curr_error < self.epsilon:\n",
    "                print('конечная разность:', Norm.get_norm(x_new - x_prev))\n",
    "                break\n",
    "            else:\n",
    "                x_prev = x_new\n",
    "            if prev_error < curr_error:\n",
    "                print('Warning: on iteration', num_of_iter, 'error was', prev_error, ' and now', curr_error)\n",
    "            prev_error = curr_error\n",
    "            num_of_iter += 1\n",
    "        return x_new\n",
    "\n",
    "\n",
    "#метод Холецкого\n",
    "class SqrtMethod:\n",
    "\n",
    "    def __init__(self, A, f):\n",
    "        self.A = A\n",
    "        self.f = f\n",
    "        self.L = np.full((n, n), 0.0)\n",
    "        self.L_T = np.full((n, n), 0.0)\n",
    "        matr_size = A.shape\n",
    "        if (len(matr_size) != 2) or (matr_size[0] != matr_size[1]):\n",
    "            print('Incorrect matrix')\n",
    "        self.n = matr_size[0]\n",
    "        self.r_arr = np.array([])\n",
    "\n",
    "    #концы включены\n",
    "    def __sum(self, end, left_index_1, left_index_2):\n",
    "        sum = 0.0\n",
    "        for k in range(end + 1):\n",
    "            sum += self.L[left_index_1, k] * self.L[left_index_2, k]\n",
    "        return sum\n",
    "\n",
    "    def __get_L_elem(self, i, j):\n",
    "        if i == j:\n",
    "            return np.sqrt(self.A[i, i] - self.__sum(i - 1, i, i))\n",
    "        else:\n",
    "            return (self.A[i, j] - self.__sum(j - 1, j, i)) / self.L[j, j]\n",
    "\n",
    "    def __fill_L(self):\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1):\n",
    "                self.L[i, j] = self.__get_L_elem(i, j)\n",
    "        self.L_T = np.copy(self.L)\n",
    "        self.L_T = np.transpose(self.L_T)\n",
    "    \n",
    "    #ytne +1 поскольку при вызове добавляется 1 тк в массиве нумерация с 0\n",
    "    def __sum_y(self, num_of_iter, cur_index, y):\n",
    "        sum = 0.0\n",
    "        for k in range(num_of_iter):\n",
    "            sum += self.L[cur_index, k] * y[k] \n",
    "        return sum\n",
    "\n",
    "    #решение уравнения Ly=f (обратный ход) \n",
    "    #L - нижне-треугольная\n",
    "    def find_y(self):\n",
    "        y = np.array([])\n",
    "        for i in range(self.n):\n",
    "            y_i = (self.f[i] - self.__sum_y(i - 1 + 1, i, y)) / self.L[i, i]   \n",
    "            y = np.append(y, y_i)\n",
    "        return y\n",
    "\n",
    "    #тут не надо + 1 (количество итераций достаточно)\n",
    "    def __sum_x(self, num_of_iter, cur_index, x):\n",
    "        sum = 0.0\n",
    "        for p in range(num_of_iter):\n",
    "            sum += self.L_T[cur_index, cur_index + p + 1] * x[cur_index + p + 1]\n",
    "        return sum\n",
    "\n",
    "    #решение уравнения L^T x = y\n",
    "    def find_x(self, y):\n",
    "        x = np.full(self.n, 0.0)\n",
    "        for k in range(self.n):\n",
    "            x[self.n - k - 1] = (y[n - k - 1] - self.__sum_x(k, self.n - k - 1, x)) \\\n",
    "                / self.L_T[n - k - 1, n - k - 1]\n",
    "        return x\n",
    "\n",
    "    def calculate(self):\n",
    "        self.__fill_L()\n",
    "        y = self.find_y()\n",
    "        x = self.find_x(y)\n",
    "        return x\n",
    "\n",
    "\n",
    "#скалярное произведение с Г=А xAy \n",
    "def scalar_by_A(x, A, y):\n",
    "    first = np.matmul(x, A)\n",
    "    return np.matmul(first, y)\n",
    "\n",
    "#подсчет минимального и максимального собственного значения\n",
    "#на википедии неправильный метод\n",
    "def calc_lambda(A):\n",
    "    num_of_iter = 200\n",
    "    y_new = np.copy(A[0])\n",
    "    y_prev = np.copy(A[0])\n",
    "    for i in range(num_of_iter):\n",
    "        y_prev = y_new\n",
    "        mult = np.matmul(A, y_prev) \n",
    "        y_new = mult                                      #/ Norm.get_norm(mult) #деление на норму помогает избежать переполнения\n",
    "    return  Norm.get_norm(y_new) / Norm.get_norm(y_prev)  #scalar_by_A(np.transpose(y_new), A, y_new) / scalar_by_A(np.transpose(y_prev), A, y_prev) \n",
    "\n",
    "#если перемножить получится единичная матрица с точностью до 10^-18\n",
    "def determine_koef(A):\n",
    "    rev_A = np.linalg.inv(A)\n",
    "    return Norm.get_norm(A) * Norm.get_norm(rev_A)\n",
    "\n",
    "def get_line(line_num):\n",
    "    line = np.array([])\n",
    "    for j in range(n):\n",
    "        if line_num == j:\n",
    "            line = np.append(line, diag)\n",
    "        else:    \n",
    "            line = np.append(line, 1 / (line_num + j + 2))\n",
    "    return line\n",
    "\n",
    "def generate_matrix():\n",
    "    matr = get_line(0)\n",
    "    for i in range(n - 1):\n",
    "        line = get_line(i + 1)\n",
    "        matr = np.vstack((matr, line))\n",
    "    return matr\n",
    "\n",
    "def generate_rhs():\n",
    "    rhs = np.array([])\n",
    "    for i in range(n):\n",
    "        rhs = np.append(rhs, 1 / (i + 1))\n",
    "    return np.transpose(rhs)\n",
    "\n",
    "def iteration_method(A, f):\n",
    "    method = UpperRelax(A, f)\n",
    "    method.calculate()\n",
    "\n",
    "def main():\n",
    "    A = generate_matrix()\n",
    "    f = generate_rhs()\n",
    "    method = UpperRelax(A, f)\n",
    "    ans_iter = method.calculate()\n",
    "    print('Ответ методом верхних релаксаций:', ans_iter)\n",
    "    straight_method = SqrtMethod(A, f)\n",
    "    ans_straight = straight_method.calculate()\n",
    "    print('Ответ методом Холецкого:', ans_straight)\n",
    "    print('Невязка:', method.r_arr)\n",
    "    print('')\n",
    "    print('Число обусловленности', determine_koef(A))\n",
    "    print('Максиммальное собственное значение:', calc_lambda(A))\n",
    "    print('Минимальное собственное значение через A^-1:', 1 / calc_lambda(np.linalg.inv(A)))\n",
    "    #print('Минимальное собственное значение через A^T:', calc_lambda(np.transpose(A)))\n",
    "    num, vec =  np.linalg.eigh(A)\n",
    "    print('')\n",
    "    print('Реальные собственные значения для :', num)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
